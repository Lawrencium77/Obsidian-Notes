These notes are based on [this](https://pythonspeed.com/articles/python-multiprocessing/) blog that Ellena sent round.

## Some Code That Should Work, But Doesn't

Consider this program:

```python
import logging
from threading import Thread
from queue import Queue
from logging.handlers import QueueListener, QueueHandler
from multiprocessing import Pool

def setup_logging():
	"""
    Logs get written to a queue, and then a thread reads
    from that queue and writes messages to a file:
    """
    queue_ = Queue() 

	# Create thread to read from the queue, and forward to file 
	# handler
    QueueListener(queue_, logging.FileHandler("out.log")).start()

	# Sets up logging system to send log messages to the 
	# specified queue
    logging.getLogger().addHandler(QueueHandler(queue_))

    # Parent process runs a thread that logs messages
    def write_logs():
        while True:
            logging.error("hello, I just did something")
    Thread(target=write_logs).start()

# These log statements get sent to the queue as well
def runs_in_subprocess():
    print("About to log...")
    logging.error("hello, I did something")
    print("...logged")

if __name__ == '__main__':
    setup_logging()

    # Meanwhile, we start a process pool that writes some
    # logs. We do this in a loop to make race condition more
    # likely to be triggered.
    while True:
        with Pool() as pool:
            pool.apply(runs_in_subprocess)
```

Here's what this program does:

1. In the parent process, log messages are generated by a thread. These are routed to a queue, and another thread reads from the queue and writes these to a log file, `out.log`.
2. Then, we start a process pool and log messages in one of the subprocesses.

If we run this program in Linux, it freezes:

```
About to log...
...logged
About to log...
...logged
About to log...
<at this point the program freezes>
```

Why?

## The Problem with Just Forking
Python starts a pool of processes using [fork()](../../Computing/Concurrency/Educative%20Course/Fork,%20Spawn,%20and%20Forkserver.md). This seems convenient, but can cause the deadlock we just saw. 

### fork() Copies Everything in Memory
When you do a `fork()`, it copies everything in memory. That includes any global variables you've set in imported Python modules.

### But It Doesn't Copy Everything
In particular, one thing that `fork()` **doesn't** copy is **threads**:

```python
from threading import Thread, enumerate
from os import fork
from time import sleep

# Start a thread:
Thread(target=lambda: sleep(60)).start()

if fork():
    print("The parent process has {} threads".format(
        len(enumerate())))
else:
    print("The child process has {} threads".format(
        len(enumerate())))
```

This gives:

```
The parent process has 2 threads
The child process has 1 threads
```

As [this](https://www.ibm.com/docs/fr/aix/7.1?topic=programming-process-duplication-termination) IBM page puts it:


> The **fork** subroutine duplicates the parent process, but duplicates only the calling thread; the child process is a single-threaded process. The calling thread of the parent process becomes the initial thread of the child process; it may not be the initial thread of the parent process. 

## How This Explains Our Problem
Here's why the original program is deadlocking:

1. Whenever the thread in the parent process writes a log message, it adds it to a `Queue`. This involves acquiring a `Lock`.
2. If the `fork()` happens at the wrong time, the lock is copied in an acquired state (the lock has been acquired by the `write_logs()` thread).
3. So when the child process writes a log message, it tries to write it to the queue but the lock is already acquired. So we get a deadlock.

## Solution: Stop Plain `fork()`ing
Python's `multiprocessing` library has three ways of creating new processes: [Fork, Spawn, and Forkserver](../../Computing/Concurrency/Educative%20Course/Fork,%20Spawn,%20and%20Forkserver.md). Using `spawn()` involves an `execve` call, which solves our problem since module state isn't inherited by child processes.

The **TLDR** here is that fork is, generally speaking, bad. Eventually, this will get fixed:

> * Starting in Python 3.12, you'll get a `DeprecationWarning` indicating that `fork()` will stop being the default in 3.14
> * In Python 3.14, the default will be changed to either `spawn()` or `forksever()`.




