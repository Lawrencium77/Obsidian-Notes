Processes communicate with each other and with the kernel. Linux supports multiple **Inter-Process Communication** mechanisms. **Signals** and **pipes** are two examples.

```toc
```

## Signals
Signals are used to communicate some event to one or more processes. They could be generated by a keyboard interrupt or an error condition such as the process attempting to access a non-existent location in its virtual memory. They're also used by shells to signal job control commands to their child processes.

There are a set of defined signals that can be generated by processes in the system, provided they have the correct privileges. You can list a systems set of signals with  `kill -l`:

```
HUP INT QUIT ILL TRAP ABRT BUS FPE KILL USR1 SEGV USR2 PIPE ALRM TERM 16 CHLD CONT STOP TSTP TTIN TTOU URG XCPU XFSZ VTALRM PROF WINCH POLL 30 SYS
```

Processes can choose to ignore most signals, with two exceptions:

* `SIGSTOP`, which causes a process to halt;
* `SIGKILL`, which causes a process to exit.

Otherwise, a process can choose how it wants to handle the various signals. Signals have no inherent relative priorities. If two signals are generated for a process at the same time, they may be handled in any order. Also, there is no mechanism for handling multiple signals of the same kind. There is no way a process can tell if it received 1 or 42 `SIGCONT` signals.

> [!INFO] 
> The `kill` command is more general than simply killing a process. It can be used to send *any* signal to a process.

> [!INFO]
> Typing Ctrl + C causes `SIGINT` to be sent to a signal. It can be caught and ignored.

Linux implements signals with information stored in a process's `task_struct`. The currently pending signals are kept in a `signal` field with a mask of blocked signals held in `blocked`. The `task_struct` points to a `sigaction` data structure that describes how the process handles every possible signal. `sigaction` contains, amongst other things, the address of a routine that will handle the signal or a flag which tells Linux that the process either wishes to ignore the signal or let the kernel handle the signal for it.

The following sketch summarises these ideas:

![|700](_attachments/Screenshot%202022-12-18%20at%2014.18.50.png)

Sending a signal is implemented by setting the appropriate bit in the `task_struct`'s `signal` field (of the recipient process). If the process is waiting but interruptible, then it is woken up by changing its state to Running. This ensures that the scheduler will consider the process to be run next time the system schedules.
The signal isn't presented to the process immediately after they're generated. It must wait until the process is running again. Every time a process exits from a syscall, its `signal` and `blocked` fields are checked and, if there are any unblocked signals, they can now be delivered. 
This may seem unreliable. But every process is making syscalls, all of the time. 

If a signal's handler is set to the default action, then the kernel will handle it. For instance, the `SIGSTOP` signal's default handler will change the current process's state to Stopped and then run the scheduler to select a new process to run. 
Alternatively, the process may have specified its own signal handler. This is a routine which will be called whenever the signal is generated and the `sigaction` structure holds the address of this routine.

Not every process in the system can send signals to every other process, although the kernel and *super users* can. Normal processes can only send signals to processes with the same `uid` and `gid` or to processes in the same process group[^fn1].

## Pipes
The common linux shells allow redirection. For instance:

```bash
ls | less
```

Pipes are unidirectional byte streams[^fn2] which connect the standard out from one process into the standard input of another process. Neither process is aware of this redirection, and it behaves just as it would normally. It is the shell that sets up these temporary pipes between the processes.

In Linux, a pipe is implemented using two `file` data structures which both point to the same temporary VFS inode, which itself points to a physical page in memory:

![|500](_attachments/Screenshot%202022-12-17%20at%2013.33.09.png)

The `f_op` field of the `file` data structure is a pointer to a vector of routine addresses; one for each function you may wish to perform on a file. In the above figure, Process 1 contains a routine for writing to the pipe, and Process 2 contains a routine for reading from the pipe.

These routines hide the differences from the generic system calls which read and write to ordinary files. As process 1 writes to the pipe, bytes are copied into the shared data page. When process 2 reads from the pipe, bytes are copied from the shared data page. Linux must synchronise access to the pipe; it must ensure the reader and writer of the pipe are in step.

To do this, Linux uses locks, wait queues and signals.

First, when the writer wants to write to the pipe it used the standard write library functions. These all pass file descriptors into the process's set of `file` data structures, each one representing an open file or, in this case, an open pipe. The Linux syscall uses the write routine pointed at by the `file` data structure describing this pipe.

That write routine uses information in the VFS inode representing the pipe to manage the write request. If there is enough room to write all of the bytes into the pipe, and assuming the pipe isn't locked by its reader, then Linux locks the pipe for the writer and copies the bytes to be written from the process's address space into the shared data page.
If the pipe is locked by the reader, or there's not enough room do the data, then the current process is made to sleep on the pipe inode's wait queue and the scheduler is called such that another process can run. It is interruptible such that it can receive signals and will be woken up by the reader when there's enough room to write data or when the pipe is unlocked.
When the data has been written, the pipe's VFS inode is unlocked and any waiting readers sleeping on the inode's wait queu will themselves be woken up.

Reading data from the pipe is a very similar process to writing it.

#### Some Clarification
A bit more Googling led to some quite interesting bits of info. I've summarised what I learned here:

> * Pipes consist of two `file` data structures, a VFS inode and a shared data page.
> * They're temporary objects.
> * They avoid the need for temporary files by using OS memory to buffer the data transferred between processes.
> * The size of the shared data page is limited, so process 1 cannot produce vastly more data than process 2 has consumed; it will be made to wait for process 2 to catch up.
> * Process 1 and process 2 execute concurrently.
> * Suppose we run `ls | less`. It is the **shell** that forks the process of the piped commands. It is **not** the case that the `ls` process forks the process that performs the `less` command. Indeed, the processes of `ls` and `less` haven't anything in common other than that the stdout of the former is piped to stdin of the latter.
> * Most files are stored on disk, not RAM. The fact that RAM is volatile makes it inappropriate for storing files. *Some* temporary files are stored in RAM but these are exceptions rather than the rule. Pipes do not write data to a file, or temporary file. They use a buffer in memory to temporarily store data as it's transferred. To be clear: this means that "Data Page" in the above diagram is stored in main memory.
> * These pipes that we've discussed so far are actually [anonymous pipes](https://en.wikipedia.org/wiki/Pipeline_(Unix)).
> * These differ from [named pipes](https://en.wikipedia.org/wiki/Named_pipe), which involve the creation of a file.



## Sockets
These are related to networking. Could be worth coming back round to them!



















[^fn1]: What are these?

[^fn2]: This sounds fancy but it really isn't. They're just a flow of information in one direction.